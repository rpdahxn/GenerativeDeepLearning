{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "03_VAE.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN38wj9/2LgvYi4rQJsSDHg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rpdahxn/GenerativeDeepLearning/blob/main/03_VAE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.2.1 첫 번째 AE"
      ],
      "metadata": {
        "id": "dXjJGQlITAxr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "Pl0np5w8LVu8"
      },
      "outputs": [],
      "source": [
        "AE = Autoencoder(\n",
        "    input_dim = (28, 28, 1),\n",
        "    encoder_conv_filters = [32, 64, 64, 64],\n",
        "    encoder_conv_kernel_size = [3, 3, 3, 3],\n",
        "    encoder_conv_strides = [1, 2, 2, 1],  # stride = 2로 출력의 크기를 줄인다.\n",
        "    decoder_conv_t_filters = [64, 64, 32, 1],\n",
        "    decoder_conv_t_kernel_size = [3, 3, 3, 3],\n",
        "    decoder_conv_t_strides = [1, 2, 2, 1],\n",
        "    z_dim = 2\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "AE.encoder.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xULJpP4hToOh",
        "outputId": "2d48ddfb-82e4-4c87-e823-78267d8a5567"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " encoder_input (InputLayer)  [(None, 28, 28, 1)]       0         \n",
            "                                                                 \n",
            " encoder_conv_0 (Conv2D)     (None, 28, 28, 32)        320       \n",
            "                                                                 \n",
            " leaky_re_lu_14 (LeakyReLU)  (None, 28, 28, 32)        0         \n",
            "                                                                 \n",
            " encoder_conv_1 (Conv2D)     (None, 14, 14, 64)        18496     \n",
            "                                                                 \n",
            " leaky_re_lu_15 (LeakyReLU)  (None, 14, 14, 64)        0         \n",
            "                                                                 \n",
            " encoder_conv_2 (Conv2D)     (None, 7, 7, 64)          36928     \n",
            "                                                                 \n",
            " leaky_re_lu_16 (LeakyReLU)  (None, 7, 7, 64)          0         \n",
            "                                                                 \n",
            " encoder_conv_3 (Conv2D)     (None, 7, 7, 64)          36928     \n",
            "                                                                 \n",
            " leaky_re_lu_17 (LeakyReLU)  (None, 7, 7, 64)          0         \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 3136)              0         \n",
            "                                                                 \n",
            " encoder_output (Dense)      (None, 2)                 6274      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 98,946\n",
            "Trainable params: 98,946\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "AE.decoder.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0c983A0yWeTz",
        "outputId": "93ee46ea-82ba-4605-ff7a-9205c91d8f43"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " decoder_input (InputLayer)  [(None, 2)]               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 3136)              9408      \n",
            "                                                                 \n",
            " reshape_2 (Reshape)         (None, 7, 7, 64)          0         \n",
            "                                                                 \n",
            " decoder_conv_t_0 (Conv2DTra  (None, 7, 7, 64)         36928     \n",
            " nspose)                                                         \n",
            "                                                                 \n",
            " leaky_re_lu_18 (LeakyReLU)  (None, 7, 7, 64)          0         \n",
            "                                                                 \n",
            " decoder_conv_t_1 (Conv2DTra  (None, 14, 14, 64)       36928     \n",
            " nspose)                                                         \n",
            "                                                                 \n",
            " leaky_re_lu_19 (LeakyReLU)  (None, 14, 14, 64)        0         \n",
            "                                                                 \n",
            " decoder_conv_t_2 (Conv2DTra  (None, 28, 28, 32)       18464     \n",
            " nspose)                                                         \n",
            "                                                                 \n",
            " leaky_re_lu_20 (LeakyReLU)  (None, 28, 28, 32)        0         \n",
            "                                                                 \n",
            " decoder_conv_t_3 (Conv2DTra  (None, 28, 28, 1)        289       \n",
            " nspose)                                                         \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 28, 28, 1)         0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 102,017\n",
            "Trainable params: 102,017\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.2.2 인코더\n",
        "Autoencoder 클래스 중 인코더 부분"
      ],
      "metadata": {
        "id": "FiLPTNHXZk8q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 인코더의 입력 이미지 정의\n",
        "encoder_input = Input(shape = self.input_dim, name = \"encoder_input\")\n",
        "\n",
        "x = encoder_input\n",
        "\n",
        "for i in range(self.n_layers_encoder):\n",
        "  conv_layer = Conv2D(\n",
        "      filters = self.encoder_conv_filters[i],\n",
        "      kernel_size = self.encoder_conv_kernel_size[i],\n",
        "      strides = self.encoder_conv_strides[i],\n",
        "      padding = 'same',\n",
        "      name = 'encoder_conv_' + str(i)\n",
        "  )\n",
        "\n",
        "  x = conv_layer(x)\n",
        "  x = LeakyReLU(x)\n",
        "\n",
        "shape_before_flattening = K.int_shape(x)[1:]\n",
        "x = Flatten()(x)\n",
        "\n",
        "# Dense층으로 벡터를 2차원 잠재 공간으로 연결\n",
        "encoder_output = Dense(self.z_dim, name = 'encoder_output')(x)\n",
        "self.encoder = Model(encoder_input, encoder_output)"
      ],
      "metadata": {
        "id": "IR52AcnMWnAc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.2.3 디코더\n",
        "Autoencoder 클래스 중 디코더 부분"
      ],
      "metadata": {
        "id": "zbbIc5awaoAs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 디코더의 입력 즉, 잠개 공간의 포인트를 정의한다.\n",
        "decoder_input = Input(shape = (self.z_dim,), name = 'decoder_input')\n",
        "\n",
        "# 입력을 Dense층에 연결\n",
        "x = Dense(np.prod(shape_before_flattening))(decoder_output)\n",
        "# 전치 합성곱 층에 주입할 수 있도록 벡터를 다차원 텐서로 바꾼다.\n",
        "x = Reshape(shape_before_flattening)(x)  \n",
        "\n",
        "for i in range(self.n_layers_decoder):\n",
        "  conv_t_layer = Conv2DTranspose(\n",
        "      filters = self.decoder_conv_t_filters[i],\n",
        "      kernel_size = self.decoder_conv_t_kernel_size[i],\n",
        "      strides = self.decoder_conv_t_strides[i],\n",
        "      padding = 'same',\n",
        "      name = 'decoder_conv_t' + str(i)\n",
        "  )\n",
        "\n",
        "  x = conv_t_layer(i)\n",
        "\n",
        "  if i < self.n_layers_decoder - 1:\n",
        "    x = LeakyReLU(x)\n",
        "  else:\n",
        "    x = Activation('sigmoid')(x)\n",
        "\n",
        "decoder_output = x\n",
        "\n",
        "# 잠재 공간의 한 포인트를 받아 원본 이미지 차원으로 디코딩\n",
        "self.decoder = Model(decoder_input, decoder_output)"
      ],
      "metadata": {
        "id": "Z5bFmOGsaqNS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.2.4 인코더와 디코더 연결하기"
      ],
      "metadata": {
        "id": "1qWNMcEXhnKr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_input = encoder_input\n",
        "model_output = decoder(encoder_output)\n",
        "self.model = Model(model_input, model_output)"
      ],
      "metadata": {
        "id": "fluqzI9wffWG"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### 컴파일\n",
        "optimizer = Adam(lr = learning_rate)\n",
        "\n",
        "def r_loss(y_true, y_pred):\n",
        "  return K.mean(K.square(y_true - y_pred), axis = [1, 2, 3])\n",
        "\n",
        "self.model.compile(optimizer = optimizer, loss = r_loss)"
      ],
      "metadata": {
        "id": "gggZfjgnhEcA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "self.model.fit(\n",
        "    x_train, y_train, batch_size = batch_size, shuffle = True, epochs = 10, callbacks = callbacks_list\n",
        ")"
      ],
      "metadata": {
        "id": "dRse2L52iBuJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.4 VAE 만들기\n",
        "### 3.4.1 인코더\n",
        "VAE 클래스 중 인코더 부분"
      ],
      "metadata": {
        "id": "c9246d5Ztiax"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_input = Input(shape = self.input_dim, name = 'encoder_input')\n",
        "\n",
        "x = encoder_input\n",
        "\n",
        "for i in range(self.n_layers_encoder):\n",
        "  conv_layer = Conv2D(\n",
        "      filters = self.encoder_conv_filters[i],\n",
        "      kernel_size = self.encoder_conv_kernel_size[i],\n",
        "      strides = self.encoder_conv_strides[i],\n",
        "      padding = 'same',\n",
        "      name = 'encoder_conv_' + str(i)\n",
        "  )\n",
        "\n",
        "  x = conv_layer(x)\n",
        "\n",
        "  if self.use_batch_norm:\n",
        "    x = BatchNormalization()(x)\n",
        "\n",
        "  x = LeakyReLU()(x)\n",
        "  if self.use_dropout:\n",
        "    x = Dropout(rate = 0.25)(x)\n",
        "\n",
        "shape_before_flattening = K.int_shape(x)[1:]\n",
        "x = Flatten()(x)\n",
        "\n",
        "# Flatten층을 바로 2차원 잠재 공간에 연결하지 않고 mu층과 log_var 층에 연결\n",
        "self.mu = Dense(self.z_dim, name = 'mu')(x)\n",
        "self.log_var = Dense(self.z_dim, name = 'log_var')(x)\n",
        "\n",
        "encoder_mu_log_var = Model(encoder_input, (self.mu, self.log_var))\n",
        "\n",
        "def sampling(args):\n",
        "  mu, log_var = args\n",
        "  epsilon = K.random_normal(shape = K.shape(mu), mean = 0, stddev = 1.)\n",
        "  return mu + K.exp(log_var / 2) * epsilon\n",
        "\n",
        "# Lambda 층이 잠재 공간에서 mu와 log_var로 정의되는 정규분포로부터 포인트 z를 샘플링한다.\n",
        "encoder_output = Lambda(sampling, name = 'encoder_output')([self.mu, self.log_var])\n",
        "\n",
        "# 이 모델은 입력 이미지를 받아 mu와 log_var로 정의된 정규 분포에서 한 포인트를 샘플링하여 2차원 잠재 공간으로 인코딩한다.\n",
        "encoder = Model(encoder_input, encoder_output)"
      ],
      "metadata": {
        "id": "na4Wt9Tntjow"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}